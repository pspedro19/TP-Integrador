
Este repositorio contiene el cuaderno `TP_1_2_3.ipynb`  [aquí](https://colab.research.google.com/drive/16YJat7W2HBI4IyK_3y6JSnxdi9YYeWJU?usp=sharing). , `tpi_parte4.ipynb` [aquí](https://colab.research.google.com/drive/13xHucLjHcN1O3g7JEj2OhnvxiwWQvwXc?usp=sharing).




# TP_1_2_3: Trabajo de Integración de Python y Numpy


## Resumen

En este trabajo practico se abordan diversos ejercicios que ilustran operaciones matemáticas y de procesamiento de datos con Python y Numpy. Los principales temas cubiertos son:

- **Normas de Vectores**: Cálculo de normas como \(l_0\), \(l_1\), \(l_2\) y \(l_{\infty}\) para matrices.
- **Métricas de Clasificación**: Evaluación de precisión, recall y exactitud en clasificación binaria.
- **División de Datos**: Herramienta para segmentar datos en conjuntos de entrenamiento, validación y prueba.
- **Problema de Regresión**: Creación de un dataset de regresión, adición de outliers y visualización de su impacto en modelos de regresión.
- **Análisis de Regresión Multivariante**: Simulaciones para analizar el efecto de variables no informativas en coeficientes de regresión.

## Funciones y Métodos Destacados

- **Normas de Vectores**: Herramientas en Numpy para calcular distintas normas vectoriales.
- **Métricas de Clasificación**: Métodos para calcular TP, TN, FP y FN con Numpy.
- **División de Datos**: Función `split` para particionar datasets.
- **Problema de Regresión**: Procedimientos para generar datasets de regresión y añadir outliers.

## Visualización

Para las visualizaciones, el cuaderno se apoya en las bibliotecas Seaborn y Matplotlib.

## Descenso del Gradiente para Regresión Lineal

El cuaderno explora la regresión lineal, enfocándose en el Error Cuadrático Medio (MSE) como función de coste, y presenta implementaciones en Python para el cálculo del gradiente y técnicas de descenso del gradiente.

## Clasificador de Rostros con GMM

Se presenta un clasificador de rostros basado en Modelos de Mezcla Gaussiana (GMM). Utilizando el conjunto de datos de Rostros de Olivetti, se entrenan GMMs para cada individuo y se selecciona el modelo óptimo basado en el Criterio de Información Bayesiano (BIC).

---

# Trabajo Integrador Parte 4

Este TP se centra en el análisis y modelado de datos relacionados con enfermedades cardíacas.

## Descripción del Código

### Contenido Principal

- El cuaderno introduce el "Trabajo Integrador Parte 4", un proyecto de análisis de datos.
- Se analizan tres datasets: "Pokemon", "Heart Disease" y "Challenger USA Space Shuttle O-Ring Data Set".
- Se detallan instrucciones para la importación de librerías y carga de datos.

### Análisis Exploratorio y Preprocesamiento

Se realiza un análisis exploratorio inicial, y se abordan técnicas de preprocesamiento como imputación, codificación y reducción de dimensiones.

### Balanceo de Clases

Se destaca la importancia del balanceo de clases y se introduce la técnica SMOTE para equilibrar las clases en el dataset.

### Modelos y Evaluación

Se discuten varios modelos de machine learning y se proporcionan detalles sobre su entrenamiento y evaluación.



